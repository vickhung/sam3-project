# @package _global_
defaults:
  - _self_

# ============================================================================
# SAM3-Small V2 Training on COCO
# 
# Architecture: 16 ViT layers, 16 Text layers, full 1008 resolution
# Dataset: COCO val2017 (5K images, 80 categories)
# ============================================================================

# ============================================================================
# Paths
# ============================================================================
paths:
  dataset_root: /home/vkwk/cursor/linux setup/sam3-project/data/coco
  experiment_log_dir: /home/vkwk/cursor/linux setup/sam3-project/experiments/sam3_small_coco
  bpe_path: /home/vkwk/cursor/linux setup/sam3-project/sam3/assets/bpe_simple_vocab_16e6.txt.gz

# ============================================================================
# Dataset Configuration  
# ============================================================================
dataset:
  # COCO val2017 for training (5K images) - using val as train for quick iteration
  train_img_folder: ${paths.dataset_root}/val2017
  train_ann_file: ${paths.dataset_root}/annotations/instances_val2017.json
  # Use same for validation (we'll split manually if needed)
  val_img_folder: ${paths.dataset_root}/val2017
  val_ann_file: ${paths.dataset_root}/annotations/instances_val2017.json

  # Training transforms
  train_transforms:
    - _target_: sam3.train.transforms.basic_for_api.ComposeAPI
      transforms:
        - _target_: sam3.train.transforms.segmentation.DecodeRle
        - _target_: sam3.train.transforms.basic_for_api.RandomResizeAPI
          sizes:
            _target_: sam3.train.transforms.basic.get_random_resize_scales
            size: ${scratch.resolution}
            min_size: 400
            rounded: false
          max_size:
            _target_: sam3.train.transforms.basic.get_random_resize_max_size
            size: ${scratch.resolution}
          square: true
          consistent_transform: false
        - _target_: sam3.train.transforms.basic_for_api.PadToSizeAPI
          size: ${scratch.resolution}
          consistent_transform: false
        - _target_: sam3.train.transforms.basic_for_api.ToTensorAPI
        - _target_: sam3.train.transforms.basic_for_api.NormalizeAPI
          mean: ${scratch.train_norm_mean}
          std: ${scratch.train_norm_std}

  # Validation transforms
  val_transforms:
    - _target_: sam3.train.transforms.basic_for_api.ComposeAPI
      transforms:
        - _target_: sam3.train.transforms.basic_for_api.RandomResizeAPI
          sizes: ${scratch.resolution}
          max_size:
            _target_: sam3.train.transforms.basic.get_random_resize_max_size
            size: ${scratch.resolution}
          square: true
          consistent_transform: false
        - _target_: sam3.train.transforms.basic_for_api.ToTensorAPI
        - _target_: sam3.train.transforms.basic_for_api.NormalizeAPI
          mean: ${scratch.train_norm_mean}
          std: ${scratch.train_norm_std}

  # Loss configuration
  loss:
    _target_: sam3.train.loss.sam3_loss.Sam3LossWrapper
    matcher: ${scratch.matcher}
    o2m_weight: 2.0
    o2m_matcher:
      _target_: sam3.train.matcher.BinaryOneToManyMatcher
      alpha: 0.3
      threshold: 0.4
      topk: 4
    use_o2m_matcher_on_o2m_aux: false
    loss_fns_find:
      - _target_: sam3.train.loss.loss_fns.Boxes
        weight_dict:
          loss_bbox: 5.0
          loss_giou: 2.0
      - _target_: sam3.train.loss.loss_fns.IABCEMdetr
        weak_loss: false
        weight_dict:
          loss_ce: 20.0
          presence_loss: 20.0
        pos_weight: 10.0
        alpha: 0.25
        gamma: 2
        use_presence: true
        pos_focal: false
        pad_n_queries: 100
        pad_scale_pos: 1.0
    loss_fn_semantic_seg: null
    scale_by_find_batch_size: ${scratch.scale_by_find_batch_size}

# ============================================================================
# Scratch (Helper Parameters)
# ============================================================================
scratch:
  # SAM3-Small V2: Full resolution, 16 ViT layers
  resolution: 1008
  d_model: 256
  enable_segmentation: false  # Start with detection only

  # Image normalization
  train_norm_mean: [0.5, 0.5, 0.5]
  train_norm_std: [0.5, 0.5, 0.5]
  val_norm_mean: [0.5, 0.5, 0.5]
  val_norm_std: [0.5, 0.5, 0.5]

  # Training parameters - optimized for 8GB GPU
  train_batch_size: 1
  val_batch_size: 1
  gradient_accumulation_steps: 8  # Effective batch = 8
  num_train_workers: 4
  num_val_workers: 2
  max_ann_per_img: 100

  # Learning rate - fine-tuned for pretrained weights
  lr_transformer: 8e-5        # 8e-4 * 0.1
  lr_vision_backbone: 2.5e-5  # 2.5e-4 * 0.1
  lr_language_backbone: 5e-6  # 5e-5 * 0.1
  lrd_vision_backbone: 0.9
  wd: 0.1

  # Scheduler
  scheduler_timescale: 50
  scheduler_warmup: 100
  scheduler_cooldown: 50

  # Matcher
  matcher:
    _target_: sam3.train.matcher.BinaryHungarianMatcherV2
    focal: true
    cost_class: 2.0
    cost_bbox: 5.0
    cost_giou: 2.0
    alpha: 0.25
    gamma: 2
    stable: false
  scale_by_find_batch_size: true

  # Position encoding
  pos_embed:
    _target_: sam3.model.position_encoding.PositionEmbeddingSine
    num_pos_feats: ${scratch.d_model}
    normalize: true
    scale: null
    temperature: 10000

  # Collate functions
  collate_fn:
    _target_: sam3.train.data.collator.collate_fn_api
    _partial_: true
    repeats: 1
    dict_key: all
    with_seg_masks: ${scratch.enable_segmentation}

  collate_fn_val:
    _target_: sam3.train.data.collator.collate_fn_api
    _partial_: true
    repeats: 1
    dict_key: default
    with_seg_masks: ${scratch.enable_segmentation}

  # Postprocessor for evaluation
  original_box_postprocessor:
    _target_: sam3.eval.postprocessors.PostProcessImage
    max_dets_per_img: -1
    use_original_ids: true
    use_original_sizes_box: true
    use_presence: true

# ============================================================================
# Trainer Configuration
# ============================================================================
trainer:
  _target_: sam3.train.trainer.Trainer
  skip_saving_ckpts: false
  empty_gpu_mem_cache_after_eval: true
  skip_first_val: false
  max_epochs: 20  # Quick training run
  accelerator: cuda
  seed_value: 42
  val_epoch_freq: 2
  mode: train
  gradient_accumulation_steps: ${scratch.gradient_accumulation_steps}

  distributed:
    backend: nccl
    find_unused_parameters: true
    gradient_as_bucket_view: true

  loss:
    all: ${dataset.loss}
    default:
      _target_: sam3.train.loss.sam3_loss.DummyLoss

  data:
    train:
      _target_: sam3.train.data.torch_dataset.TorchDataset
      dataset:
        _target_: sam3.train.data.sam3_image_dataset.Sam3ImageDataset
        transforms: ${dataset.train_transforms}
        load_segmentation: ${scratch.enable_segmentation}
        max_ann_per_img: ${scratch.max_ann_per_img}
        multiplier: 1
        max_train_queries: 10000
        max_val_queries: 10000
        training: true
        use_caching: false
        img_folder: ${dataset.train_img_folder}
        ann_file: ${dataset.train_ann_file}
      shuffle: true
      batch_size: ${scratch.train_batch_size}
      num_workers: ${scratch.num_train_workers}
      pin_memory: true
      drop_last: true
      collate_fn: ${scratch.collate_fn}

    val:
      _target_: sam3.train.data.torch_dataset.TorchDataset
      dataset:
        _target_: sam3.train.data.sam3_image_dataset.Sam3ImageDataset
        load_segmentation: ${scratch.enable_segmentation}
        coco_json_loader:
          _target_: sam3.train.data.coco_json_loaders.COCO_FROM_JSON
          include_negatives: true
          category_chunk_size: 10
          _partial_: true
        img_folder: ${dataset.val_img_folder}
        ann_file: ${dataset.val_ann_file}
        transforms: ${dataset.val_transforms}
        max_ann_per_img: ${scratch.max_ann_per_img}
        multiplier: 1
        training: false
      shuffle: false
      batch_size: ${scratch.val_batch_size}
      num_workers: ${scratch.num_val_workers}
      pin_memory: true
      drop_last: false
      collate_fn: ${scratch.collate_fn_val}

  # MODEL - SAM3-Small V2 with 16 ViT layers
  model:
    _target_: training.sam3_small.model_builder.build_sam3_small
    bpe_path: ${paths.bpe_path}
    device: cpu
    eval_mode: false
    enable_segmentation: ${scratch.enable_segmentation}

  meters:
    val:
      default:
        detection:
          _target_: sam3.eval.coco_writer.PredictionDumper
          iou_type: bbox
          dump_dir: ${launcher.experiment_log_dir}/predictions
          merge_predictions: true
          postprocessor: ${scratch.original_box_postprocessor}
          gather_pred_via_filesys: false
          maxdets: 100
          pred_file_evaluators:
            - _target_: sam3.eval.coco_eval_offline.CocoEvaluatorOfflineWithPredFileEvaluators
              gt_path: ${dataset.val_ann_file}
              tide: false
              iou_type: bbox

  optim:
    amp:
      enabled: true  # Use mixed precision for memory efficiency
      amp_dtype: bfloat16

    optimizer:
      _target_: torch.optim.AdamW
      _partial_: true

    gradient_clip:
      _target_: sam3.train.optim.optimizer.GradientClipper
      max_norm: 0.1
      norm_type: 2

    param_group_modifiers:
      - _target_: sam3.train.optim.optimizer.layer_decay_param_modifier
        _partial_: true
        layer_decay_value: ${scratch.lrd_vision_backbone}
        apply_to: backbone.vision_backbone.trunk
        overrides:
          - pattern: '*pos_embed*'
            value: 1.0

    options:
      lr:
        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${scratch.lr_transformer}
            timescale: ${scratch.scheduler_timescale}
            warmup_steps: ${scratch.scheduler_warmup}
            cooldown_steps: ${scratch.scheduler_cooldown}
        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${scratch.lr_vision_backbone}
            timescale: ${scratch.scheduler_timescale}
            warmup_steps: ${scratch.scheduler_warmup}
            cooldown_steps: ${scratch.scheduler_cooldown}
          param_names:
            - backbone.vision_backbone.*
        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${scratch.lr_language_backbone}
            timescale: ${scratch.scheduler_timescale}
            warmup_steps: ${scratch.scheduler_warmup}
            cooldown_steps: ${scratch.scheduler_cooldown}
          param_names:
            - backbone.language_backbone.*

      weight_decay:
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: ${scratch.wd}
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.0
          param_names:
            - '*bias*'
          module_cls_names: [torch.nn.LayerNorm]

  checkpoint:
    save_dir: ${launcher.experiment_log_dir}/checkpoints
    save_freq: 2

  logging:
    tensorboard_writer:
      _target_: sam3.train.utils.logger.make_tensorboard_logger
      log_dir: ${launcher.experiment_log_dir}/tensorboard
      flush_secs: 120
    wandb_writer: null
    log_dir: ${launcher.experiment_log_dir}/logs
    log_freq: 20

# ============================================================================
# Launcher Configuration
# ============================================================================
launcher:
  num_nodes: 1
  gpus_per_node: 1
  experiment_log_dir: ${paths.experiment_log_dir}
  multiprocessing_context: spawn

submitit:
  use_cluster: false
  port_range: [10000, 65000]

